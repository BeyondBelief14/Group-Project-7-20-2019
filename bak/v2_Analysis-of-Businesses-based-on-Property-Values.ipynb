#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import numpy as np
import matplotlib as plt
import requests
import json
# API Keys
from config import api_key

import time


# In[2]:


#Google Places Types: https://developers.google.com/places/web-service/supported_types

#TODO: Can we incorporate this list into the loop so this list can change without changing the code
types = ['bank']#, 'library', 'park', 'liquor_store', 'hospital']


# question 1: what are the most
# 

# In[3]:


# Read in the Dallas County Appraisal District (DCAD) property values file

file = "dcad_combined-Copy1.csv"

#create DataFrame
dcad_df = pd.read_csv(file, usecols=['PROPERTY_ZIPCODE', 'TOT_VAL'])
dcad_df.head(5)


# In[4]:


#add column for 5 digit zipcode
dcad_df['ZIPCODE'] = dcad_df['PROPERTY_ZIPCODE'].astype(str).str[:5]


# In[5]:


#Group Property Values by Zipcode
zip_group = dcad_df.groupby('ZIPCODE')['TOT_VAL']

zip_group = zip_group.mean().to_frame('TOT_VAL')

#Sort the Zipcodes by propert values so we can easily get the top/bottom
zip_group.sort_values(by='TOT_VAL', ascending=False, inplace=True)

zip_group_df = zip_group.reset_index()


# In[6]:


#Add columns to DataFrame to store business data
zip_group_df['Lat'] = "" 
zip_group_df["Lng"] = ""
zip_group_df["City"] = ""
zip_group_df["State"] = ""
zip_group_df = zip_group_df.rename(columns={"ZIPCODE": "Zipcode"})
zip_group_df["MeanPropertyValue"] = zip_group_df["TOT_VAL"].map("${:,.0f}".format)


# In[7]:


#Preview 5 Zipcodes with highest values
zip_group_df.head(5)


# In[8]:


#Get 5 Zipcodes with lowest values
zip_group_df.tail(5)


# In[9]:


# create a params dict that will be updated with new zipcode each iteration
params = {"key": api_key,"keyword":'bank'}

# print("entering loop for iterrows")

# Loop through the zipcode pd's and run a lat/long search for each
for index, row in zip_group_df.iterrows():
    base_url = "https://maps.googleapis.com/maps/api/geocode/json"

    zipcode = row['Zipcode']

    # update address key value to zipcode
    params['address'] = zipcode

    # make request
    zips_lat_lng = requests.get(base_url, params=params)
    
    # convert to json
    zips_lat_lng = zips_lat_lng.json()
    # print(json.dumps(zips_lat_lng, indent=4, sort_keys=True))
    # print(len(zips_lat_lng['results']))
    if index > 2: 
        break

# print("finishing loop for iterrows")

# In[10]:


### base_url = "https://maps.googleapis.com/maps/api/place/textsearch/json"


    # update address key value to zipcode
### params = {"key": api_key,"types":'restaurant',"query" : "75201"}

base_url = "https://maps.googleapis.com/maps/api/geocode/json"
params = {"key": api_key,"keyword":'bank'}
params['address'] = zipcode

    # make request
zips_lat_lng = requests.get(base_url, params=params)
    
    # convert to json
zips_lat_lng = zips_lat_lng.json()
# print(json.dumps(zips_lat_lng, indent=4, sort_keys=True))
# len(zips_lat_lng)


# In[ ]:

# print(zips_lat_lng['results'])

#loop through address to find city
for i in zips_lat_lng['results'][0]['address_components']:
  if i['types'][0] == 'locality':
      zip_group_df.loc[index, "City"] = i['long_name']

#loop though address to find state
for i in zips_lat_lng['results'][0]['address_components']:
  if i['types'][0] == 'administrative_area_level_1':
      zip_group_df.loc[index, "State"] = i['short_name']
zip_group_df.loc[index, "Lat"] = zips_lat_lng["results"][0]["geometry"]["location"]["lat"]
zip_group_df.loc[index, "Lng"] = zips_lat_lng["results"][0]["geometry"]["location"]["lng"]

print("after address components filter")

# Visualize to confirm lat lng appear
zip_group_df.head(3)


# In[ ]:


# params dictionary to update each iteration
# def findPlaces(loc=("35.701474","51.405288"),radius=4000, pagetoken = None):
#     lat, lng = loc
#     type = "restaurant"
#     url = "https://maps.googleapis.com/maps/api/place/json?location={lat},{lng}&radius={radius}&type={type}&key={APIKEY}{pagetoken}".format(lat = lat, lng = lng, radius = radius, type = type,APIKEY = APIKEY, pagetoken = "&pagetoken="+pagetoken if pagetoken else "")
#     print(url)
#     response = requests.get(url)
#     res = json.loads(response.text)
#     # print(res)
#     print("here results ---->>> ", len(res["results"]))

#     for result in res["results"]:
#         info = ";".join(map(str,[result["name"],result["geometry"]["location"]["lat"],result["geometry"]["location"]["lng"],result.get("rating",0),result["place_id"]]))
#     print(info)
#     pagetoken = res.get("next_page_token",None)





for each_type in types:
    params = {
        #3 mi radius. A Zipcode is not returned in the results, so we cannot 
        #match against our zipcode without doing a reverse lookup for every result
        "radius": 4828,
        "types": each_type,
        "keyword": "bank",
        "key": api_key
    }
    
    #variables for the specific column names for the business type we are searching
    count_column = f"{each_type}_count"
    rating_column = f"{each_type}_rating"
    
    #add columns for each type we looking up
    zip_group_df[count_column] = ""
    zip_group_df[rating_column] = ""


    # Use the lat/lng we recovered to search for businesses
    for index, row in zip_group_df.iterrows():

        rating_sum = 0
        rating_count = 0

        # get lat, lng from df
        lat = row["Lat"]
        lng = row["Lng"]

        # change location each iteration while leaving original params in place
        #params["location"] = f"32.8326,-96.7976" #testing 1 lat, lng
        params["location"] = f"{lat},{lng}"

        #Google Places Search
        base_url = "https://maps.googleapis.com/maps/api/place/nearbysearch/json"

        # make request and print url
        search_results = requests.get(base_url, params=params)

        # convert to json
        search_results = search_results.json()
        #print(json.dumps(search_results, indent=4, sort_keys=True))

        results_list = search_results['results']

        #Set the business count
        zip_group_df.loc[index, count_column] = len(results_list)

        #Loop through results list to get rating for each 
        for each_result in results_list:
            #check for KeyError since not all business have a rating
            try:
                #print(f'{each_result["name"]}: {each_result["rating"]}')
                rating = each_result["rating"]
                rating_count += 1
                rating_sum += rating
            except(KeyError):
                next
        #Set Rating to 0 if there are not businesses returned
        try:
            zip_group_df.loc[index, rating_column] = rating_sum / rating_count
        except(ZeroDivisionError):
            zip_group_df.loc[index, rating_column] = 0
            
        detail_df = pd.DataFrame.from_dict(results_list, orient='columns')

        if index > 2:
            break


# In[ ]:

print("finishing nested loop")


zip_group_df.sort_values('TOT_VAL').head()


# In[ ]:


# params = {pagetoken}



params['radius'] = params['radius'] / 3

print("params: ", params['radius'])

apikey = params['key']

total = 0

def findPlaces(pagetoken = None):
    global total

    if pagetoken != None: 
        params['pagetoken'] = pagetoken
    # print(params['key'])

    response = requests.get(base_url,params=params)
    dictionary = json.loads(response.text)
    print(len(dictionary["results"]))
    total += len(dictionary["results"])

    for result in dictionary["results"]:
        # print(result)
        info = ";".join(map(str,[result["name"],result["geometry"]["location"]["lat"],result["geometry"]["location"]["lng"],result.get("rating",0),result["place_id"]]))
        # print(info)
        print(result["name"])
    pagetoken = dictionary.get("next_page_token",None)

    print("here -->> ", pagetoken)
    count = 0

    if (len(dictionary["results"]) < 20): 
        print("No more entries!")
        return None

    # while pagetoken == None and len(dictionary["results"]) == 20 and count < 5: 
    #     time.sleep(5)
    #     response = requests.get(base_url,params=params)
    #     dictionary = json.loads(response.text)
    #     pagetoken = dictionary.get("next_page_token",None)
    #     print("try again:  -->> ", pagetoken)
    #     count += 1

    return pagetoken

# In[ ]:
# time.sleep(2)

# token = findPlaces(token)



token = findPlaces()
time.sleep(5)

count = 0

while token:

    token = findPlaces(token)

    count += 1
    if count > 5:
        break
    # 
    time.sleep(5)

    # end of loop

print("total entries: ", total)

# In[ ]:




